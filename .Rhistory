# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
predicted_m2 <- predict(improved_model,test_df,type = "response")
pred1 <- rep("Fail",dim(test_df)[1])
pred1[predicted_m1 > 0.5] = "Pass"
cm1 <- table(pred1,test_df$Pass)
summary(raw_model)
summary(improved_model)
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
test_df <- read.csv(file = "Downloads/DA/Assignment/4/Test - Sheet1.csv")
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
predicted_m2 <- predict(improved_model,test_df,type = "response")
# Renaming Variables
Day1 <- up_school$Day1
Day2 <- up_school$Day2
Day3 <- up_school$Day3
Day4 <- up_school$Day4
Day5 <- up_school$Day5
Senior <- up_school$Senior
Class <- up_school$Class
Class_Prefect <- up_school$Class_Prefect
Athlete <- up_school$Athlete
popularity <- up_school$popularity
# Implement a logistic regression model on the training data.
raw_model <- glm(Class ~ Class_Prefect + Senior + Day1 + Day2 + Day3 + Day4 + Day5+Athlete+popularity,family = binomial(link = "logit"))
improved_model <- glm(Class ~Day3 + Day4+Athlete+popularity,family = binomial(link = "logit"))
summary(raw_model)
summary(improved_model)
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
# Implement a logistic regression model on the training data.
raw_model <- glm(Class ~ Class_Prefect + Senior + Day1 + Day2 + Day3 + Day4 + Day5+Athlete+popularity,family = binomial(link = "logit"))
improved_model <- glm(Class ~Day3 + Day4+Athlete+popularity,family = binomial(link = "logit"))
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
predicted_m2 <- predict(improved_model,test_df,type = "response")
pred1 <- rep("Fail",dim(test_df)[1])
pred1[predicted_m1 > 0.5] = "Pass"
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
# The dataset in SchoolData contains information to do with students in a school. We will use logistic regression to predict if these students will successfully be able to Pass the course given their attendance and other attributes.
library(caret)
set.seed(1)
school_df <- read.csv(file = "Downloads/DA/Assignment/4/School_Data")
test_df <- read.csv(file = "Downloads/DA/Assignment/4/Test - Sheet1.csv")
# Preprocessing of Data
# Sample class imbalance is sometimes an issue with logistic regression. Clearly, the training dataset has a major imbalance, as the number of Students who have passed outnumbers the students who have failed. Correct this imbalance by upsampling the records of those who have failed.
up_school <- as.data.frame(upSample(school_df[,-ncol(school_df)],as.factor(school_df$Pass)))
# Renaming Variables
Day1 <- up_school$Day1
Day2 <- up_school$Day2
Day3 <- up_school$Day3
Day4 <- up_school$Day4
Day5 <- up_school$Day5
Senior <- up_school$Senior
Class <- up_school$Class
Class_Prefect <- up_school$Class_Prefect
Athlete <- up_school$Athlete
popularity <- up_school$popularity
# Implement a logistic regression model on the training data.
raw_model <- glm(Class ~ Class_Prefect + Senior + Day1 + Day2 + Day3 + Day4 + Day5+Athlete+popularity,family = binomial(link = "logit"))
improved_model <- glm(Class ~Day3 + Day4+Athlete+popularity,family = binomial(link = "logit"))
summary(raw_model)
summary(improved_model)
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
View(test_df)
colnames(test_df)
x <- colnames(test_df)
x
x[9] <- "popularity"
colnames(test_df) <- x
View(test_df)
# When we compare the AIC values for the
predicted_m1 <- predict(raw_model,test_df,type = "response")
predicted_m2 <- predict(improved_model,test_df,type = "response")
pred1 <- rep("Fail",dim(test_df)[1])
pred1[predicted_m1 > 0.5] = "Pass"
cm1 <- table(pred1,test_df$Pass)
pred2 <- rep("Fail",dim(test_df)[1])
pred2[predicted_m2 > 0.5] = "Pass"
cm2 <- table(pred2,test_df$Pass)
cm1
cm2
summary(raw_model)
improved_model <- glm(Class ~Day1 + Day3 + Day4 + Athlete + popularity,family = binomial(link = "logit"))
summary(improved_model)
cm1
cm2
cm1 <- table(pred1,test_df$Pass,dnn = list.names("Fail","Pass"))
cm1 <- table(pred1,test_df$Pass,dnn = c("Fail","Pass"))
cm1
cm1 <- table(pred1,test_df$Pass,dnn = c("Ground Truth","Predicted"))
cm1
colnames(cm1) <- c("Fail","Pass")
cm1
confusionMatrix(cm1)
pred1 <- rep("Fail",dim(test_df)[1])
pred1[predicted_m1 >= 0.5] = "Pass"
cm1 <- table(pred1,test_df$Pass,dnn = c("Ground Truth","Predicted"))
colnames(cm1) <- c("Fail","Pass")
pred2 <- rep("Fail",dim(test_df)[1])
pred2[predicted_m2 >= 0.5] = "Pass"
cm2 <- table(pred2,test_df$Pass,dnn = c("Ground Truth","Predicted"))
colnames(cm2) <- c("Fail","Pass")
confusionMatrix(cm1)
pred1[predicted_m1 >= 0.5] = "Pass"
cm1 <- table(pred1,test_df$Pass,dnn = c("Ground Truth","Predicted"))
colnames(cm1) <- c("Fail","Pass")
pred2 <- rep("Fail",dim(test_df)[1])
pred2[predicted_m2 >= 0.5] = "Pass"
cm2 <- table(pred2,test_df$Pass,dnn = c("Ground Truth","Predicted"))
colnames(cm2) <- c("Fail","Pass")
confusionMatrix(cm1)
confusionMatrix(cm2)
colnames(cm1) <- c("Fail","Pass")
table(school_df$Pass)
table(up_school$Pass)
table(up_school$Class)
install.packages('mice')
library(class)
table(file$`Absenteeism time in hours`)
round(prop.table(table(file$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
df <- file[,1:14]
# df <- na.omit(df)
prc_n <- as.data.frame(lapply(df[,], normalize))
# summary(prc_n$Reason.for.absence)
prc_train <- prc_n[1:700,]
prc_test <- prc_n[700:740,]
prc_train_labels <- file[1:700, 15]
prc_test_labels <- file[700:740, 15]
prc_test_pred <- knn(train = prc_train, test = prc_test,cl = prc_train_labels$`Absenteeism time in hours`, k=6)
library('gmodels')
CrossTable(x=prc_test_labels$`Absenteeism time in hours`,y=prc_test_pred,prop.chisq = FALSE)
file<-read_csv("Absenteeism_at_work.csv")
library(class)
table(file$`Absenteeism time in hours`)
round(prop.table(table(file$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
df <- file[,1:14]
# df <- na.omit(df)
prc_n <- as.data.frame(lapply(df[,], normalize))
# summary(prc_n$Reason.for.absence)
prc_train <- prc_n[1:700,]
prc_test <- prc_n[700:740,]
prc_train_labels <- file[1:700, 15]
prc_test_labels <- file[700:740, 15]
prc_test_pred <- knn(train = prc_train, test = prc_test,cl = prc_train_labels$`Absenteeism time in hours`, k=6)
library('gmodels')
CrossTable(x=prc_test_labels$`Absenteeism time in hours`,y=prc_test_pred,prop.chisq = FALSE)
library(class)
table(file$`Absenteeism time in hours`)
library(readr)
library(sqldf)
library(NbClust)
library(factoextra)
library(caret)
library(class)
df<-read_csv("Absenteeism_at_work.csv")
file<-read_csv("Absenteeism_at_work.csv")
df<-read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv")
table(file$`Absenteeism time in hours`)
round(prop.table(table(file$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
df <- file[,1:14]
df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
table(file$`Absenteeism time in hours`)
table(df$`Absenteeism time in hours`)
# table(df$`Absenteeism time in hours`)
round(prop.table(table(df$`Absenteeism time in hours`)) * 100, digits = 1)
df <- df[,2:14]
# df <- na.omit(df)
normalized_df <- as.data.frame(lapply(df[,], normalize))
# summary(prc_n$Reason.for.absence)
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
train_labels <- df[1:700, 15]
train_labels <- df[1:700, 14]
train_labels <- df[1:700, 13]
test_labels <- df[700:740, 15]
train_labels <- df[1:700, 15]
df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
# table(df$`Absenteeism time in hours`)
round(prop.table(table(df$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
train_labels <- df[1:700, 15]
test_labels <- df[700:740, 15]
df <- df[,2:14]
# df <- na.omit(df)
normalized_df <- as.data.frame(lapply(df[,], normalize))
# summary(prc_n$Reason.for.absence)
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels$`Absenteeism time in hours`, k=6)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=6)
library('gmodels')
CrossTable(x=prc_test_labels$`Absenteeism time in hours`,y=prc_test_pred,prop.chisq = FALSE)
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
# Define training control
set.seed(123)
train.control <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
Fertility
# Train the model
model <- train(`Absenteeism time in hours` ~., data = df, method = "lm",
trControl = train.control)
Fertility
# Train the model
model <- train(train_labels ~., data = df, method = "lm",
trControl = train.control)
main_df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
# Train the model
model <- train( `Absenteeism time in hours`~., data = main_df, method = "lm",
trControl = train.control)
# Train the model
model <- train(`Absenteeism time in hours`~., data = main_df, method = "lm",
trControl = train.control)
# Train the model
model <- train(Absenteeism time in hours~., data = main_df, method = "lm",
trControl = train.control)
`
train.control <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# Train the model
model <- train(`Absenteeism time in hours`~., data = main_df, method = "lm",
trControl = train.control)
# Train the model
model <- train(`Absenteeism time in hours`~., data = main_df, method = "lm",trControl = train.control)
# Train the model
model <- train(main_df$`Absenteeism time in hours`, data = main_df, method = "lm",trControl = train.control)
# Train the model
model <- train(x= main_df$`Absenteeism time in hours`, data = main_df, method = "lm",trControl = train.control)
~.
# Train the model
model <- train(main_df$`Absenteeism time in hours`~., data = main_df, method = "lm",trControl = train.control)
# Train the model
model <- train(`Absenteeism time in hours`~., data = main_df, method = "lm",trControl = train.control)
# Train the model
model <- train(x = train_df, data = main_df, method = "lm",trControl = train.control)
# Train the model
model <- train(x = train_df,y = train_labels, data = main_df, method = "lm",trControl = train.control)
# Train the model
main_df <- na.omit(main_df)
model <- train(x = train_df,y = train_labels, data = main_df, method = "lm",trControl = train.control)
# Train the model
train_df <- na.omit(train_df)
model <- train(x = train_df,y = train_labels, data = main_df, method = "lm",trControl = train.control)
# Summarize the results
print(model)
# model <- train(x = train_df,y = train_labels, data = main_df, method = "lm",trControl = train.control)
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit1)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
knnFit <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=13)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
library(readr)
library(sqldf)
library(NbClust)
library(factoextra)
library(caret)
library(class)
main_df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
round(prop.table(table(df$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
train_labels <- df[1:700, 15]
test_labels <- df[700:740, 15]
df <- main_df[,2:14]
normalized_df <- as.data.frame(lapply(df[,], normalize))
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=13)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
train_labels <- df[1:700, 15]
test_labels <- df[700:740, 15]
df <- main_df[,2:14]
normalized_df <- as.data.frame(lapply(df[,], normalize))
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
train_labels <- main_df[1:700, 15]
test_labels <- main_df[700:740, 15]
df <- main_df[,2:14]
normalized_df <- as.data.frame(lapply(df[,], normalize))
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=13)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
library(readr)
library(sqldf)
library(NbClust)
library(factoextra)
library(caret)
library(class)
main_df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
round(prop.table(table(main_df$`Absenteeism time in hours`)) * 100, digits = 1)
# round(prop.table(table(main_df$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
train_labels <- main_df[1:700, 15]
test_labels <- main_df[700:740, 15]
# remove prediction column and id column
df <- main_df[,2:14]
normalized_df <- as.data.frame(lapply(df[,], normalize))
train_df <- normalized_df[1:700,]
test_df <- normalized_df[700:740,]
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
# Summarize the results
print(knnFit1)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
test_labels
train_labels
set.seed(123)
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit1)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
set.seed(123)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
set.seed(123)
knnFit1 <- train(train_df, train_labels,
"knn",
tuneLength = 5,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit1)
set.seed(123)
knnFit2 <- train(train_df, train_labels,
"knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
# Summarize the results
print(knnFit2)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=21)
library('gmodels')
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
table(test_df,test_predictions)
table(test_labels,test_predictions)
CrossTable(x=test_labels,y=test_predictions,prop.chisq = FALSE)
RMSE(test_labels,test_predictions)
RMSE(test_labels,test_predictions,na.remove=T)
RMSE(test_labels,test_predictions,na.omit=T)
View(main_df)
RMSE(test_labels,test_predictions,)
RMSE(test_labels,test_predictions)
k=table(test_df,test_predictions)
k
k=table(test_labels,test_predictions)
randIndex(k)
k=table(test_labels,test_predictions)
k
library(flexclust)
randIndex(k)
k[,c("0")]
k[,c(0)]
k[,c("0","1")]
CrossTable(x=test_labels,y=test_predictions)
# table(test_df,test_predictions)
confusionMatrix(test_predictions,test_labels)
# table(test_df,test_predictions)
confusionMatrix(test_predictions,as.factor(test_labels))
table(factor(test_predictions, levels=min(test_labels):max(test_labels)),
factor(test_labels, levels=min(test_labels):max(test_labels)))
# table(test_df,test_predictions)
confusionMatrix(factor(test_predictions, levels=min(test_labels):max(test_labels)),
factor(test_labels, levels=min(test_labels):max(test_labels)))
confusionMatrix(factor(test_predictions, levels=min(test_labels):max(test_labels)),
factor(test_labels, levels=min(test_labels):max(test_labels)))
library(readr)
library(sqldf)
library(NbClust)
library(factoextra)
library(caret)
library(class)
main_df<-data.frame(read_csv("~/Downloads/DA/Assignment/6/Absenteeism_at_work.csv"))
# round(prop.table(table(main_df$`Absenteeism time in hours`)) * 100, digits = 1)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
train_labels <- main_df[1:700, 15]
test_labels <- main_df[700:740, 15]
c <- confusionMatrix(factor(test_predictions, levels=min(test_labels):max(test_labels)),
factor(test_labels, levels=min(test_labels):max(test_labels)))
summary(c)
c.summary
c
test_predictions <- knn(train = train_df, test = test_df,cl = train_labels, k=15)
c <- confusionMatrix(factor(test_predictions, levels=min(test_labels):max(test_labels)),
factor(test_labels, levels=min(test_labels):max(test_labels)))
c
personalityComplete <- complete(tempData,1)
(table(is.na(personalityComplete)))
# There are 144 observations with missing values,the values are absent at random.
library(mice)
personalityComplete <- complete(tempData,1)
source('~/Downloads/DA/young-people-survey/youth-happiness-analysis/missingData_1.R', echo=TRUE)
pTMissingPattern <- md.pattern(personalityTraitsMissing,plot = TRUE)
table(is.na(personalityTraits$Internet.usage))
table(is.na(personalityTraits$Punctuality))
table(is.na(personalityTraits$Lying))
View(demographics)
View(demographicsComplete)
# There are 144 observations with missing values,the values are absent at random.
demMissingPattern <- md.pattern(demographicsMissing,plot = TRUE)
demMissingPattern
summary(demMissingPattern)
print(demMissingPattern)
setwd("~/Downloads/DA/young-people-survey/youth-happiness-analysis/.")
df <- read.csv("responses.csv")
